{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c3fa11",
   "metadata": {},
   "source": [
    "<b>Imports. The \"limit\" parameter in keyedvectors.load_word2vec_format will give you the n most common words </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e315568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format(r\"C:\\Users\\mikef\\Downloads\\GoogleNews-vectors-negative300.bin.gz\", binary=True, limit=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfdf4f8",
   "metadata": {},
   "source": [
    "<b>Run nltk.download() to download brown and wordnet. Only needs to be done once.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0001954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967a7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import inflect\n",
    "from nltk.corpus import brown\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2850e246",
   "metadata": {},
   "source": [
    "Some commented out test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old code for getting sentences in serial that contain inputted word\n",
    "# def sentence_word(word):\n",
    "#     word_sents = []\n",
    "#     for i in brown.sents(categories='fiction'):\n",
    "#         if word in i:\n",
    "#             word_sents.append(i)\n",
    "#     return word_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8601153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_vectors.most_similar(positive=['said'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7753ef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 - word_vectors.distance('solicitation','envelope')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cebb56",
   "metadata": {},
   "source": [
    "<h1>Main Functions</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec741fed",
   "metadata": {},
   "source": [
    "<p>Generates a list of \"semantic\" \"opposites\" of a word. List items are randomized so that not every instance of a word, say 'dog', has the same opposite on each occurence. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposite_vector(word):\n",
    "    try:\n",
    "        zz = word_vectors.most_similar(negative=[word],topn=1000)\n",
    "        random.shuffle(zz)\n",
    "        return zz\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f21fee7",
   "metadata": {},
   "source": [
    "<p>Replaces words in a sentence with their \"semantic\" \"opposites\". Only replaces words of selected part of speech categories. Input the sentence as a list, and input the desired part of speech categories as a list as well. POS categories must be inputed as follows: Noun = 'NOUN', Verb = 'VERB', Adjective = 'ADJ'. Example: opposite_sentence(['Look', 'at', 'the', 'funny', 'cat'], ['NOUN','ADJ']) will try to switch all the nouns and adjectives in the sentence \"Look at the funny cat\" with their opposites. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opposite_sentence(sentence,cats=['NOUN']): #sentence inputted as list, cats = pos categories\n",
    "    if isinstance(sentence,str):\n",
    "        return opposite_sentence(re.split(\"[ ,]\",sentence))\n",
    "    a = nlp(' '.join(sentence.copy())) #a = list-like object of words that can now be queried for their POS (eg a[0].pos_)\n",
    "    return_sent = sentence.copy()\n",
    "    replacements = []\n",
    "    \n",
    "    ###This whole 'skip' var is needed since apostrephes are considered as parts of speech.\n",
    "    ###This leads to nlp(sentence) having a longer length then sentence.split()\n",
    "    skip = 0\n",
    "    \n",
    "    for i in range(len(a)): #for each word (or punctuation) in sentence\n",
    "        pos = a[i].pos_     #get POS of word \n",
    "        if pos == 'PART':\n",
    "            skip +=1\n",
    "        if pos not in cats: #If POS not in the inputed categories then ignore it\n",
    "            continue\n",
    "        opposite_list = opposite_vector(str(a[i])) #Get the words list of opposite words\n",
    "        if opposite_list == 0:                     #Unless we can't find a list of opposite words  \n",
    "            continue\n",
    "#Now iterate over each opposite word. Try replacing it with the original word in the sentence.\n",
    "#If the opposite word takes on the same POS when replaced into the sentence, finalize it as the official replacement word\n",
    "        for opposite in [o[0] for o in opposite_list]: \n",
    "            c = return_sent.copy() #get current return sentence \n",
    "            c[i-skip] = opposite        #replace current word with opposite\n",
    "#This code may be useful if theres issues with singular/plural nouns -- will look into more later\n",
    "#             if inflect.engine().singular_noun(opposite) != False:\n",
    "#                 continue     \n",
    "            if nlp(' '.join(c))[i].pos_== pos: #check if replaced opposite has same POS or original word\n",
    "                replacements.append((i-skip,opposite)) #if so, officially replace it\n",
    "                break\n",
    "    for i in replacements: \n",
    "        return_sent[i[0]] = \"[\" + i[1] + \"]\" #i[0] is index, i[1] is string replacement\n",
    "    return return_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5862aa21",
   "metadata": {},
   "source": [
    "<h1>Display Function(s)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c5f3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_x(total_sents,cats):\n",
    "    for i in range(total_sents):\n",
    "        q = random.choice(brown.sents())\n",
    "        try:\n",
    "            a = ' '.join(q)\n",
    "            b = ' '.join(opposite_sentence(q,cats))\n",
    "            if a != b:\n",
    "                print('*********************************************')\n",
    "                print(a)\n",
    "                print()\n",
    "                print(b)\n",
    "                print('*********************************************')\n",
    "        except:\n",
    "            pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
